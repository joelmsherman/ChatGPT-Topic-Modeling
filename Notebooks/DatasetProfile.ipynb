{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9815c05",
   "metadata": {},
   "source": [
    "# Dataset Cleanup, Profiling and EDA\n",
    "This notebook provides the data cleaning, profiling and exploratory data analysis (EDA) methods used in the project.  Those methods include the following steps:\n",
    "\n",
    "1. Initial dataset import\n",
    "2. Data cleanup\n",
    "3. Profiling \n",
    "4. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b103c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4d96b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/joelmsherman/ChatGPT-Topic-Modeling/master/Data/tweets.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef645a4",
   "metadata": {},
   "source": [
    "### 1. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8550c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unnecessary columns\n",
    "df.drop(['hashtags', 'source', 'user_description', 'user_location', 'user_favourites'], axis=1, inplace=True)\n",
    "\n",
    "# Queue up datetime types\n",
    "df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True, errors='coerce')\n",
    "df['user_created'] = pd.to_datetime(df['user_created'], infer_datetime_format=True, errors='coerce')\n",
    "\n",
    "# Change dtype of followers and friends to int; set Nan to zero\n",
    "df['user_followers'] = df['user_followers'].fillna(0).astype('int')\n",
    "df['user_friends'] = df['user_friends'].fillna(0).astype('int')\n",
    "\n",
    "# Add a user duration calculated column and convert the timedelta to an int\n",
    "df.insert(5, 'user_duration_days', 0)\n",
    "df['user_duration_days'] = df['date'] - df['user_created']\n",
    "df['user_duration_days'] = df['user_duration_days'].dt.days\n",
    "df['user_duration_days'] = df['user_duration_days'].fillna(0).astype('int')\n",
    "\n",
    "# Renamed 'date' column to 'tweet_date'\n",
    "df.rename(columns={'date': 'tweet_date'}, inplace=True)\n",
    "df.rename(columns={'text': 'tweet'}, inplace=True)\n",
    "\n",
    "# Deleted columns user_created\n",
    "df.drop(['user_created'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cbedae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of simple retweets\n",
    "df = df.drop_duplicates(subset=['tweet'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e44cea",
   "metadata": {},
   "source": [
    "### 2. Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84363c6",
   "metadata": {},
   "source": [
    "The dataset contains 60,504 unique tweets (simple retweets have been removed) referencing the hashtag #ChatGPT from 35,748 different users over the period December 5, 2002, through January 2, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fec26bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60504"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique tweets\n",
    "df['tweet'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e96ec5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35748"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique user_names\n",
    "df['user_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b160a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-12-05 17:08:20+0000', tz='UTC')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Earliest tweet in df\n",
    "df['tweet_date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc38e35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-01-02 20:50:45+0000', tz='UTC')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Latest tweet in df\n",
    "df['tweet_date'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee571c3e",
   "metadata": {},
   "source": [
    "### 3. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dfdd41",
   "metadata": {},
   "source": [
    "The vast majority of tweets occured in the early part of December, with the peak at December 6, when almost 7,000 tweets about ChatGPT were sent.  Since then, the number of tweets each day has declined significantly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad6243bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df of tweets over time\n",
    "tmp_df = df[['tweet', 'tweet_date']].copy()\n",
    "tmp_df['Date'] = tmp_df['tweet_date'].dt.strftime(\"%Y-%m-%d\")\n",
    "pivot_table = tmp_df.pivot_table(\n",
    "    index=['Date'],\n",
    "    values=['tweet'],\n",
    "    aggfunc={'tweet': ['count']}\n",
    ")\n",
    "pivot_table = pivot_table.set_axis([flatten_column_header(col) for col in pivot_table.keys()], axis=1)\n",
    "df_pivot = pivot_table.reset_index()\n",
    "\n",
    "# Renamed columns Tweets\n",
    "df_pivot.rename(columns={'tweet count': 'Tweets'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb6ae208",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_61.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create line chart\n",
    "import plotly.express as px\n",
    "fig = px.line(df_pivot, x='Date', y='Tweets', line_shape='spline')\n",
    "fig.update_layout(\n",
    "    title='Tweets Over Time', \n",
    "    xaxis = dict(\n",
    "        showgrid=True, \n",
    "        rangeslider = dict(\n",
    "            visible=True, \n",
    "            thickness=0.05\n",
    "        )\n",
    "    ), \n",
    "    yaxis = dict(\n",
    "        showgrid=True\n",
    "    ), \n",
    "    legend = dict(\n",
    "        orientation='v'\n",
    "    ), \n",
    "    paper_bgcolor='#FFFFFF'\n",
    ")\n",
    "fig.show(renderer=\"iframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e5975",
   "metadata": {},
   "source": [
    "Tweets mostly came from newer users to Twitter, but the distribution of user duration was bi-modal.  The vast majority of tweets were from brand new twitter users, but a significant proportion of tweets also came from users who've been on Twitter for 5000 days or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49ab2cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_62.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(df, x='user_duration_days', histfunc='count')\n",
    "fig.update_layout(\n",
    "    title='Distribution of User Time on Twitter', \n",
    "    xaxis = dict(\n",
    "        showgrid=True, \n",
    "        rangeslider = dict(\n",
    "            visible=True, \n",
    "            thickness=0.05\n",
    "        )\n",
    "    ), \n",
    "    yaxis = dict(\n",
    "        showgrid=True\n",
    "    ), \n",
    "    legend = dict(\n",
    "        orientation='v'\n",
    "    ), \n",
    "    barmode='group', \n",
    "    paper_bgcolor='#FFFFFF'\n",
    ")\n",
    "fig.show(renderer=\"iframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3662ade2",
   "metadata": {},
   "source": [
    "Of the more than 60,000 tweets sent, only around 1,500 were from verified Twitter users.  Verified twitter users sending these tweets had more followers (147K vs. 3K), more friends (7K vs. 1K), and have been on Twitter longer (4600 vs. 2800 days) than non-Verified twitter users who sent the VAST majority of tweets about ChatGPT.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db1dc83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=7fc45404-b2ab-43b8-a4cc-d6e3238d26de style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('7fc45404-b2ab-43b8-a4cc-d6e3238d26de').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_verified</th>\n",
       "      <th>tweet count</th>\n",
       "      <th>user_followers mean</th>\n",
       "      <th>user_friends mean</th>\n",
       "      <th>user_duration_days mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>58979</td>\n",
       "      <td>2895.887197</td>\n",
       "      <td>1389.911697</td>\n",
       "      <td>2759.064379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1523</td>\n",
       "      <td>147319.854235</td>\n",
       "      <td>7259.065660</td>\n",
       "      <td>4627.869993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "  user_verified  tweet count  user_followers mean  user_friends mean  \\\n",
       "0         False        58979          2895.887197        1389.911697   \n",
       "1          True         1523        147319.854235        7259.065660   \n",
       "\n",
       "   user_duration_days mean  \n",
       "0              2759.064379  \n",
       "1              4627.869993  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Pivoted into df\n",
    "tmp_df = df[['user_verified', 'tweet']].copy()\n",
    "pivot_table = tmp_df.pivot_table(\n",
    "    index=['user_verified'],\n",
    "    values=['tweet'],\n",
    "    aggfunc={'tweet': ['count']}\n",
    ")\n",
    "pivot_table = pivot_table.set_axis([flatten_column_header(col) for col in pivot_table.keys()], axis=1)\n",
    "df_pivot = pivot_table.reset_index()\n",
    "\n",
    "# Deleted 1 row in df_pivot\n",
    "df_pivot.drop(labels=[0], inplace=True)\n",
    "\n",
    "# Pivoted into df\n",
    "tmp_df = df[['user_followers', 'user_verified']].copy()\n",
    "pivot_table = tmp_df.pivot_table(\n",
    "    index=['user_verified'],\n",
    "    values=['user_followers'],\n",
    "    aggfunc={'user_followers': ['mean']}\n",
    ")\n",
    "pivot_table = pivot_table.set_axis([flatten_column_header(col) for col in pivot_table.keys()], axis=1)\n",
    "df_pivot_1 = pivot_table.reset_index()\n",
    "\n",
    "# Deleted 1 row in df_pivot_1\n",
    "df_pivot_1.drop(labels=[0], inplace=True)\n",
    "\n",
    "# Pivoted into df\n",
    "tmp_df = df[['user_friends', 'user_verified']].copy()\n",
    "pivot_table = tmp_df.pivot_table(\n",
    "    index=['user_verified'],\n",
    "    values=['user_friends'],\n",
    "    aggfunc={'user_friends': ['mean']}\n",
    ")\n",
    "pivot_table = pivot_table.set_axis([flatten_column_header(col) for col in pivot_table.keys()], axis=1)\n",
    "df_pivot_2 = pivot_table.reset_index()\n",
    "\n",
    "# Deleted 1 row in df_pivot_2\n",
    "df_pivot_2.drop(labels=[0], inplace=True)\n",
    "\n",
    "# Pivoted into df\n",
    "tmp_df = df[['user_verified', 'user_duration_days']].copy()\n",
    "pivot_table = tmp_df.pivot_table(\n",
    "    index=['user_verified'],\n",
    "    values=['user_duration_days'],\n",
    "    aggfunc={'user_duration_days': ['mean']}\n",
    ")\n",
    "pivot_table = pivot_table.set_axis([flatten_column_header(col) for col in pivot_table.keys()], axis=1)\n",
    "df_pivot_3 = pivot_table.reset_index()\n",
    "\n",
    "# Deleted 1 row in df_pivot_3\n",
    "df_pivot_3.drop(labels=[0], inplace=True)\n",
    "\n",
    "# Merged df_pivot and df_pivot_1 into df6\n",
    "temp_df = df_pivot_1.drop_duplicates(subset=['user_verified']) # Remove duplicates so lookup merge only returns first match\n",
    "df6 = df_pivot.merge(temp_df, left_on=['user_verified'], right_on=['user_verified'], how='left', suffixes=['_df_pivot', '_df_pivot_1'])\n",
    "\n",
    "# Merged df6 and df_pivot_2 into df7\n",
    "temp_df = df_pivot_2.drop_duplicates(subset=['user_verified']) # Remove duplicates so lookup merge only returns first match\n",
    "df7 = df6.merge(temp_df, left_on=['user_verified'], right_on=['user_verified'], how='left', suffixes=['_df6', '_df_pivot_2'])\n",
    "\n",
    "# Merged df7 and df_pivot_3 into df8\n",
    "temp_df = df_pivot_3.drop_duplicates(subset=['user_verified']) # Remove duplicates so lookup merge only returns first match\n",
    "df8 = df7.merge(temp_df, left_on=['user_verified'], right_on=['user_verified'], how='left', suffixes=['_df7', '_df_pivot_3'])\n",
    "\n",
    "# Renamed df8 to Summary_Stats\n",
    "Summary_Stats = df8\n",
    "Summary_Stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19a331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
